{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy import optimize as op\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body-length</th>\n",
       "      <th>wing-length</th>\n",
       "      <th>body-width</th>\n",
       "      <th>wing-width</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body-length  wing-length  body-width  wing-width  type\n",
       "0          3.0          5.0         1.6         0.2     0\n",
       "1          3.2          4.7         1.6         0.2     0\n",
       "2          3.4          4.6         1.4         0.3     0\n",
       "3          3.6          5.0         1.4         0.2     0\n",
       "4          4.1          5.2         1.5         0.1     0"
      ]
     },
     "execution_count": 1234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the data from the file\n",
    "import os  \n",
    "path = os.getcwd() + '/owlsNumLabels.csv'  \n",
    "data = pd.read_csv(path, sep=\",\" ,header=None, names=['body-length','wing-length', 'body-width','wing-width' , 'type'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=[\"LongEaredOwl\",\"SnowyOwl\",\"BarnOwl\"]\n",
    "\n",
    "# this function returns the correct label for a given input as the labels were changed to [0,1,2] in preprocessing\n",
    "# 0=LongEaredOwl\n",
    "# 1=SnowyOwl\n",
    "# 2=BarnOwl\n",
    "def returnLabelString(number):\n",
    "    return labels[number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "LABELS=[0,1,2]\n",
    "Lambda=0.01 # lambda = the learning rate\n",
    "\n",
    "numColumns = data.shape[1]\n",
    "\n",
    "# num of examples\n",
    "m = data.shape[0]\n",
    "# number of features\n",
    "n = numColumns-1\n",
    "# number of labels\n",
    "k = len(np.unique(data['type']))\n",
    "\n",
    "# initialise arrays to all ones, with added column of 1's\n",
    "X = np.ones((m,n+1))\n",
    "y = np.array((m,1))\n",
    "\n",
    "# set values in the y vector\n",
    "y=data[\"type\"].values\n",
    "\n",
    "# set values in the X vector, leaving column 0: as all 1's\n",
    "X[:,1]= data[\"body-length\"].values\n",
    "X[:,2]= data[\"wing-length\"].values\n",
    "X[:,3]= data[\"body-width\"].values\n",
    "X[:,4]= data[\"wing-width\"].values\n",
    "\n",
    "# #perform normalisation on the data\n",
    "# ((value - mean)/ stdDeviation)\n",
    "for j in range(n):\n",
    "    X[:, j+1] = (X[:, j+1] - X[:,j+1].mean())/(X[:,j+1].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function takes in two lists, compares the values and outputs the accuracy at which they are similar\n",
    "# Parameters predicted= the list of class values/labels that the model produced\n",
    "# actual= the actual class values/labels of the data\n",
    "def calculateAccuracy(predicted, actual):\n",
    "    sum=0\n",
    "    length=len(predicted)\n",
    "    for i in range(length):\n",
    "        if predicted[i]==actual[i]:\n",
    "            sum=sum+1\n",
    "    tot=(sum/length)\n",
    "    return tot # return the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic regression cost function\n",
    "test=0\n",
    "def Cost(theta, X, y):\n",
    "    m = len(y) # the number of samples input\n",
    "    hTheta = sigmoid(X.dot(theta)) # probability y=1: given that its parameterised by theta\n",
    "    tc = np.copy(theta) #tc = theta copy we will be using \n",
    "    tc[0] = 0 # we dont regularize theta[0] as its used as a bias term\n",
    "\n",
    "    return (1/m) * (-y.T.dot(np.log(hTheta)) - (1-y).T.dot(np.log(1-hTheta))) + ((Lambda/(2*m))*np.sum(tc**2))\n",
    "    # return the value produced by the equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient Descent \n",
    "def Gradient(theta, X, y):\n",
    "    m=X.shape[0] # number of samples\n",
    "    n=X.shape[1] # number of features\n",
    "    theta = theta.reshape((n, 1)) # reshape theta into a n*1 vector mat the matrix multiplication to work\n",
    "    y = y.reshape((m, 1)) # need to reshape the target vector to a m*1 vector\n",
    "    hTheta = sigmoid(X.dot(theta)) # # probability y=1: given that its parameterised by theta\n",
    "    tc = np.copy(theta) # tc= theta copy\n",
    "    tc[0]=0 # we dont regularize theta[0] as its used as a bias term\n",
    "    grad=((1/m) * X.T.dot(hTheta-y)) + ((Lambda/m)*tc)# calculate the gradient\n",
    "    \n",
    "    return grad # return the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt  \n",
    "#Optimal theta \n",
    "def logisticRegression(X, y, theta):\n",
    "    result = opt.fmin_tnc(func=Cost, x0=theta, fprime=Gradient, args=(X, y)) \n",
    "\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funciton which returns the mean of an input list\n",
    "# parameter = lst (the list you wish to average, this implementation assumes it contains ints or floats)\n",
    "def getMean(lst):\n",
    "    return sum(lst)/len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 95.121951 %\n",
      "Test Accuracy 100.000000 %\n",
      "Test Accuracy 92.682927 %\n",
      "Test Accuracy 100.000000 %\n",
      "Test Accuracy 95.121951 %\n",
      "Test Accuracy 95.121951 %\n",
      "Test Accuracy 97.560976 %\n",
      "Test Accuracy 92.682927 %\n",
      "Test Accuracy 95.121951 %\n",
      "Test Accuracy 95.121951 %\n",
      "Average Accuracy = 95.853659 +/- 3.658537\n",
      "Average Accuracy = 91.707317 +/- 4.878049\n"
     ]
    }
   ],
   "source": [
    "f = open('LogisticOutput.txt','w') # file the output will be wrote to\n",
    "# specify the number of times you want the model to be tested on the data\n",
    "numFolds=10\n",
    "scores=[] # list to keep track of the algorithms average accuarcy\n",
    "skScores=[] # list to keep track of the sklearn implemenations average accuracy\n",
    "#runResults=[]\n",
    "\n",
    "# iterate over the data the specified number of amounts\n",
    "# in each, calculate the accuracy and output the pr\n",
    "for j in range(numFolds):\n",
    "    all_theta = np.zeros((k,n+1))# initialise all_theta to store the theta values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "    \n",
    "    lr= LogisticRegression().fit(X_train,y_train)\n",
    "    yhat = lr.predict(X_test)\n",
    "    skAcc=calculateAccuracy(y_test, yhat)\n",
    "    skScores.append(skAcc*100)\n",
    "    #One vs all\n",
    "    i = 0\n",
    "    for samp in LABELS:\n",
    "        value=np.array(y_train==samp,dtype=int)\n",
    "        # value acts as the temporary y vector, where values are all set to 1 or 0,\n",
    "        # i.e. 1 for the label being tested, and rest are set to 0\n",
    "        optimalTheta = logisticRegression(X_train, value, np.zeros((n+1,1)))\n",
    "        all_theta[i] = optimalTheta\n",
    "        i=i+1\n",
    "        \n",
    "    Probabilities = sigmoid(X_test.dot(all_theta.T)) #probability that eacy is 1, for each label\n",
    "    predicts = [LABELS[np.argmax(Probabilities[i, :])] for i in range(X_test.shape[0])]# get the prediction(highest value[0,1,2]) for each sample\n",
    "        \n",
    "    acc=calculateAccuracy(y_test, predicts)\n",
    "    scores.append(acc*100)\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        f.write(\"predicted label: %s - actual label : %s\" % (returnLabelString(p[i]),returnLabelString(y_test[i])) +\"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    print(\"Test Accuracy %f \" %(acc * 100) +\"%\")\n",
    "    \n",
    "for l in range(numFolds):\n",
    "    f.write(\"\\n\\tAccuracy of fold %d = %f\" %(l+1,scores[l]))\n",
    "\n",
    "# calculate the mean accuracy of the iterations and its range (plus and minus values)\n",
    "# for the implemented algorithm\n",
    "mean = getMean(scores)\n",
    "indexH, highest = max(enumerate(scores), key=operator.itemgetter(1))\n",
    "indexL, lowest = min(enumerate(scores), key=operator.itemgetter(1))\n",
    "avgDiff=((highest-lowest) /2)\n",
    "print(\"Average Accuracy = %f +/- %f\"  %(mean,avgDiff))\n",
    "\n",
    "# write the results of the implemented model to the .txt file\n",
    "f.write(\"\\n\\t Implemented algorithm\")\n",
    "f.write(\"\\nBest Accuracy was iteration number %d, with %f Accuracy \" %(indexH,highest))\n",
    "f.write(\"\\nWorst Accuracy was iteration number %d, with %f Accuracy \" %(indexL,lowest))\n",
    "f.write(\"\\n\"+\"Average Accuracy = %f (Percent) +/- %f (Percent)\"  %(mean,avgDiff)+\"\\n\")\n",
    "\n",
    "# compute the average and range of the values for the sklearn model\n",
    "skMean = getMean(skScores)\n",
    "indexHsk, highestSK = max(enumerate(skScores), key=operator.itemgetter(1))\n",
    "indexLsk, lowestSK = min(enumerate(skScores), key=operator.itemgetter(1))\n",
    "avgDiffSk=((highestSK-lowestSK) /2)\n",
    "print(\"Average Accuracy = %f +/- %f\"  %(skMean,avgDiffSk))\n",
    "\n",
    "# output the results of the sklearn logistic regresssion to the .txt file\n",
    "f.write(\"\\n\\t Sklearn algorithm\")\n",
    "f.write(\"\\nBest Accuracy was iteration number %d, with %f Accuracy \" %(indexHsk,highestSK))\n",
    "f.write(\"\\nWorst Accuracy was iteration number %d, with %f Accuracy \" %(indexLsk,lowestSK))\n",
    "f.write(\"\\n\"+\"Average Accuracy = %f (Percent) +/- %f (Percent)\"  %(skMean,avgDiffSk))\n",
    "\n",
    "f.close()# close the file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
